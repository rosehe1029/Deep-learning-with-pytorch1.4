{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq2seq with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype=torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S:symbol that shows starting of decoding input\n",
    "#E:Symol that shows  starting of decoding output\n",
    "#P:Symol that will fill in black sequence if current batch data size is short than time steps\n",
    "sentences=['ich mochte ein bier bier  P','S i want a beer','i want a beer E']\n",
    "\n",
    "word_list=\" \".join(sentences).split()\n",
    "word_list=list(set(word_list))\n",
    "word_dict={w:i for i,w in enumerate(word_list)}\n",
    "number_dict={w:i for i,w in enumerate(word_list)}\n",
    "n_class=len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter \n",
    "n_hidden=128\n",
    "\n",
    "def make_batch(sentences):\n",
    "    input_batch=[np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch=[np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "    target_batch=[[word_dict[n] for  n in sentences[2].split()]]\n",
    "    #make tensor\n",
    "    return Variable(torch.Tensor(input_batch)),Variable(torch.Tensor(output_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:78: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0400 cost = 0.000512\n",
      "Epoch: 0800 cost = 0.000166\n",
      "Epoch: 1200 cost = 0.000082\n",
      "Epoch: 1600 cost = 0.000049\n",
      "Epoch: 2000 cost = 0.000032\n",
      "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "\n",
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "number_dict = {i: w for i, w in enumerate(word_list)}\n",
    "n_class = len(word_dict)  # vocab list\n",
    "\n",
    "# Parameter\n",
    "n_hidden = 128\n",
    "\n",
    "def make_batch(sentences):\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
    "\n",
    "    # make tensor\n",
    "    return Variable(torch.Tensor(input_batch)), Variable(torch.Tensor(output_batch)), Variable(torch.LongTensor(target_batch))\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "\n",
    "        # Linear for attention\n",
    "        self.attn = nn.Linear(n_hidden, n_hidden)\n",
    "        self.out = nn.Linear(n_hidden * 2, n_class)\n",
    "\n",
    "    def forward(self, enc_inputs, hidden, dec_inputs):\n",
    "        enc_inputs = enc_inputs.transpose(0, 1)  # enc_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "        dec_inputs = dec_inputs.transpose(0, 1)  # dec_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "\n",
    "        # enc_outputs : [n_step, batch_size, num_directions(=1) * n_hidden], matrix F\n",
    "        # enc_hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs, hidden)\n",
    "\n",
    "        trained_attn = []\n",
    "        hidden = enc_hidden\n",
    "        n_step = len(dec_inputs)\n",
    "        model = Variable(torch.empty([n_step, 1, n_class]))\n",
    "\n",
    "        for i in range(n_step):  # each time step\n",
    "            # dec_output : [n_step(=1), batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            # hidden : [num_layers(=1) * num_directions(=1), batch_size(=1), n_hidden]\n",
    "            dec_output, hidden = self.dec_cell(dec_inputs[i].unsqueeze(0), hidden)\n",
    "            attn_weights = self.get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step]\n",
    "            trained_attn.append(attn_weights.squeeze().data.numpy())\n",
    "\n",
    "            # matrix-matrix product of matrices [1,1,n_step] x [1,n_step,n_hidden] = [1,1,n_hidden]\n",
    "            context = attn_weights.bmm(enc_outputs.transpose(0, 1))\n",
    "            dec_output = dec_output.squeeze(0)  # dec_output : [batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            context = context.squeeze(1)  # [1, num_directions(=1) * n_hidden]\n",
    "            model[i] = self.out(torch.cat((dec_output, context), 1))\n",
    "\n",
    "        # make model shape [n_step, n_class]\n",
    "        return model.transpose(0, 1).squeeze(0), trained_attn\n",
    "\n",
    "    def get_att_weight(self, dec_output, enc_outputs):  # get attention weight one 'dec_output' with 'enc_outputs'\n",
    "        n_step = len(enc_outputs)\n",
    "        attn_scores = Variable(torch.zeros(n_step))  # attn_scores : [n_step]\n",
    "\n",
    "        for i in range(n_step):\n",
    "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])\n",
    "\n",
    "        # Normalize scores to weights in range 0 to 1\n",
    "        return F.softmax(attn_scores).view(1, 1, -1)\n",
    "\n",
    "    def get_att_score(self, dec_output, enc_output):  # enc_outputs [batch_size, num_directions(=1) * n_hidden]\n",
    "        score = self.attn(enc_output)  # score : [batch_size, n_hidden]\n",
    "        return torch.dot(dec_output.view(-1), score.view(-1))  # inner product make scalar value\n",
    "\n",
    "input_batch, output_batch, target_batch = make_batch(sentences)\n",
    "\n",
    "# hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "hidden = Variable(torch.zeros(1, 1, n_hidden))\n",
    "\n",
    "model = Attention()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train\n",
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    output, _ = model(input_batch, hidden, output_batch)\n",
    "\n",
    "    loss = criterion(output, target_batch.squeeze(0))\n",
    "    if (epoch + 1) % 400 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Test\n",
    "test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
    "test_batch = Variable(torch.Tensor(test_batch))\n",
    "predict, trained_attn = model(input_batch, hidden, test_batch)\n",
    "predict = predict.data.max(1, keepdim=True)[1]\n",
    "print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])\n",
    "\n",
    "# Show Attention\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.matshow(trained_attn, cmap='viridis')\n",
    "ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
